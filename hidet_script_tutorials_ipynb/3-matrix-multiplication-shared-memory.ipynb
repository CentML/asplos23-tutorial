{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;64m#\u001B[39m\u001B[38;5;64minclude\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;248;03m<stdint.h>\u001B[39;00m\n",
      "\u001B[38;5;64m#\u001B[39m\u001B[38;5;64minclude\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;248;03m<cuda_fp16.h>\u001B[39;00m\n",
      "\u001B[38;5;64m#\u001B[39m\u001B[38;5;64minclude\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;248;03m<cuda_bf16.h>\u001B[39;00m\n",
      "\u001B[38;5;64m#\u001B[39m\u001B[38;5;64minclude\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;248;03m<hidet/runtime/cuda_context.h>\u001B[39;00m\n",
      "\u001B[38;5;64m#\u001B[39m\u001B[38;5;64minclude\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;248;03m<hidet/runtime/cpu_context.h>\u001B[39;00m\n",
      "\u001B[38;5;19mtypedef\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;37mfloat\u001B[39m\u001B[38;5;250m \u001B[39mtfloat32_t;\n",
      "\u001B[38;5;64m#\u001B[39m\u001B[38;5;64mdefine __float_to_tf32(x) (x)\u001B[39m\n",
      "\u001B[38;5;19mextern\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;130m\"\u001B[39m\u001B[38;5;130mC\u001B[39m\u001B[38;5;130m\"\u001B[39m\u001B[38;5;250m \u001B[39m{\n",
      "\n",
      "\u001B[38;5;19m__global__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;37mvoid\u001B[39m\u001B[38;5;250m \u001B[39m__launch_bounds__(\u001B[38;5;30m1024\u001B[39m)\u001B[38;5;250m \u001B[39mhidet_kernel(\u001B[38;5;37mfloat\u001B[39m\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;37m__restrict__\u001B[39m\u001B[38;5;250m \u001B[39ma,\u001B[38;5;250m \u001B[39m\u001B[38;5;37mfloat\u001B[39m\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;37m__restrict__\u001B[39m\u001B[38;5;250m \u001B[39mb,\u001B[38;5;250m \u001B[39m\u001B[38;5;37mfloat\u001B[39m\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;37m__restrict__\u001B[39m\u001B[38;5;250m \u001B[39mc)\u001B[38;5;250m \u001B[39m{\n",
      "\u001B[38;5;250m  \u001B[39m\u001B[38;5;37m__shared__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;37mfloat\u001B[39m\u001B[38;5;250m \u001B[39msmem_a[\u001B[38;5;30m4096\u001B[39m];\n",
      "\u001B[38;5;250m  \u001B[39m\u001B[38;5;37m__shared__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;37mfloat\u001B[39m\u001B[38;5;250m \u001B[39msmem_b[\u001B[38;5;30m4096\u001B[39m];\n",
      "\u001B[38;5;250m  \u001B[39m\u001B[38;5;37mfloat\u001B[39m\u001B[38;5;250m \u001B[39macc\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m\u001B[38;5;30m0.0f\u001B[39m;\n",
      "\u001B[38;5;250m  \u001B[39m\u001B[38;5;19mfor\u001B[39m\u001B[38;5;250m \u001B[39m(\u001B[38;5;37mint32_t\u001B[39m\u001B[38;5;250m \u001B[39mk_tile\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m\u001B[38;5;30m0\u001B[39m;\u001B[38;5;250m \u001B[39m(k_tile\u001B[38;5;250m \u001B[39m<\u001B[38;5;250m \u001B[39m\u001B[38;5;30m8\u001B[39m);\u001B[38;5;250m \u001B[39mk_tile\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m(k_tile\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m\u001B[38;5;30m1\u001B[39m))\u001B[38;5;250m \u001B[39m{\n",
      "\u001B[38;5;250m    \u001B[39m\u001B[38;5;37mint32_t\u001B[39m\u001B[38;5;250m \u001B[39mtid\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m((\u001B[38;5;37mint\u001B[39m)\u001B[38;5;37mthreadIdx\u001B[39m.x\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m((\u001B[38;5;37mint\u001B[39m)\u001B[38;5;37mthreadIdx\u001B[39m.y\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m));\n",
      "\u001B[38;5;250m    \u001B[39m\u001B[38;5;19mfor\u001B[39m\u001B[38;5;250m \u001B[39m(\u001B[38;5;37mint32_t\u001B[39m\u001B[38;5;250m \u001B[39mi\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m\u001B[38;5;30m0\u001B[39m;\u001B[38;5;250m \u001B[39m(i\u001B[38;5;250m \u001B[39m<\u001B[38;5;250m \u001B[39m\u001B[38;5;30m4\u001B[39m);\u001B[38;5;250m \u001B[39mi\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m(i\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m\u001B[38;5;30m1\u001B[39m))\u001B[38;5;250m \u001B[39m{\n",
      "\u001B[38;5;250m      \u001B[39msmem_a[(((tid\u001B[38;5;250m \u001B[39m/\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m128\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m((i\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(tid\u001B[38;5;250m \u001B[39m%\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)))]\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39ma[(((((\u001B[38;5;37mint\u001B[39m)\u001B[38;5;37mblockIdx\u001B[39m.y\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(tid\u001B[38;5;250m \u001B[39m/\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m))\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m1024\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m((k_tile\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m128\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m((i\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(tid\u001B[38;5;250m \u001B[39m%\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m))))];\n",
      "\u001B[38;5;250m    \u001B[39m}\u001B[38;5;250m \u001B[39m\n",
      "\u001B[38;5;250m    \u001B[39m\u001B[38;5;19mfor\u001B[39m\u001B[38;5;250m \u001B[39m(\u001B[38;5;37mint32_t\u001B[39m\u001B[38;5;250m \u001B[39mi_1\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m\u001B[38;5;30m0\u001B[39m;\u001B[38;5;250m \u001B[39m(i_1\u001B[38;5;250m \u001B[39m<\u001B[38;5;250m \u001B[39m\u001B[38;5;30m4\u001B[39m);\u001B[38;5;250m \u001B[39mi_1\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m(i_1\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m\u001B[38;5;30m1\u001B[39m))\u001B[38;5;250m \u001B[39m{\n",
      "\u001B[38;5;250m      \u001B[39msmem_b[((((i_1\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(tid\u001B[38;5;250m \u001B[39m/\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m))\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(tid\u001B[38;5;250m \u001B[39m%\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m))]\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39mb[((((k_tile\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m128\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m((i_1\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(tid\u001B[38;5;250m \u001B[39m/\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)))\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m1024\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(((\u001B[38;5;37mint\u001B[39m)\u001B[38;5;37mblockIdx\u001B[39m.x\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(tid\u001B[38;5;250m \u001B[39m%\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)))];\n",
      "\u001B[38;5;250m    \u001B[39m}\u001B[38;5;250m \u001B[39m\n",
      "\u001B[38;5;250m    \u001B[39m\u001B[38;5;34m__syncthreads\u001B[39m();\n",
      "\u001B[38;5;250m    \u001B[39m\u001B[38;5;19mfor\u001B[39m\u001B[38;5;250m \u001B[39m(\u001B[38;5;37mint32_t\u001B[39m\u001B[38;5;250m \u001B[39mk\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m\u001B[38;5;30m0\u001B[39m;\u001B[38;5;250m \u001B[39m(k\u001B[38;5;250m \u001B[39m<\u001B[38;5;250m \u001B[39m\u001B[38;5;30m128\u001B[39m);\u001B[38;5;250m \u001B[39mk\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m(k\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m\u001B[38;5;30m1\u001B[39m))\u001B[38;5;250m \u001B[39m{\n",
      "\u001B[38;5;250m      \u001B[39macc\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m(acc\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(smem_a[(((\u001B[38;5;37mint\u001B[39m)\u001B[38;5;37mthreadIdx\u001B[39m.y\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m128\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39mk)]\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39msmem_b[((k\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(\u001B[38;5;37mint\u001B[39m)\u001B[38;5;37mthreadIdx\u001B[39m.x)]));\n",
      "\u001B[38;5;250m    \u001B[39m}\u001B[38;5;250m \u001B[39m\n",
      "\u001B[38;5;250m    \u001B[39m\u001B[38;5;34m__syncthreads\u001B[39m();\n",
      "\u001B[38;5;250m  \u001B[39m}\u001B[38;5;250m \u001B[39m\n",
      "\u001B[38;5;250m  \u001B[39mc[(((((\u001B[38;5;37mint\u001B[39m)\u001B[38;5;37mblockIdx\u001B[39m.y\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(\u001B[38;5;37mint\u001B[39m)\u001B[38;5;37mthreadIdx\u001B[39m.y)\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m1024\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(((\u001B[38;5;37mint\u001B[39m)\u001B[38;5;37mblockIdx\u001B[39m.x\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(\u001B[38;5;37mint\u001B[39m)\u001B[38;5;37mthreadIdx\u001B[39m.x))]\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39macc;\n",
      "}\n",
      "\n",
      "\u001B[38;5;19m__host__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;37mvoid\u001B[39m\u001B[38;5;250m \u001B[39mhidet_matmul(\u001B[38;5;37mint32_t\u001B[39m\u001B[38;5;250m \u001B[39mnum_args,\u001B[38;5;250m \u001B[39m\u001B[38;5;37mint32_t\u001B[39m\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;37m__restrict__\u001B[39m\u001B[38;5;250m \u001B[39marg_types,\u001B[38;5;250m \u001B[39m\u001B[38;5;37mvoid\u001B[39m*\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;37m__restrict__\u001B[39m\u001B[38;5;250m \u001B[39margs)\u001B[38;5;250m \u001B[39m{\n",
      "\u001B[38;5;250m  \u001B[39massert(((\u001B[38;5;37mvoid\u001B[39m)\u001B[38;5;130m\"\u001B[39m\u001B[38;5;130mExpect 3 arguments\u001B[39m\u001B[38;5;130m\"\u001B[39m,\u001B[38;5;250m \u001B[39m(num_args\u001B[38;5;250m \u001B[39m==\u001B[38;5;250m \u001B[39m\u001B[38;5;30m3\u001B[39m)));\n",
      "\u001B[38;5;250m  \u001B[39massert(((\u001B[38;5;37mvoid\u001B[39m)\u001B[38;5;130m\"\u001B[39m\u001B[38;5;130mThe 0-th argument should be TensorPointerType(tensor(float32, [1024, 1024]))\u001B[39m\u001B[38;5;130m\"\u001B[39m,\u001B[38;5;250m \u001B[39m(arg_types[\u001B[38;5;30m0\u001B[39m]\u001B[38;5;250m \u001B[39m==\u001B[38;5;250m \u001B[39m\u001B[38;5;30m3\u001B[39m)));\n",
      "\u001B[38;5;250m  \u001B[39massert(((\u001B[38;5;37mvoid\u001B[39m)\u001B[38;5;130m\"\u001B[39m\u001B[38;5;130mThe 1-th argument should be TensorPointerType(tensor(float32, [1024, 1024]))\u001B[39m\u001B[38;5;130m\"\u001B[39m,\u001B[38;5;250m \u001B[39m(arg_types[\u001B[38;5;30m1\u001B[39m]\u001B[38;5;250m \u001B[39m==\u001B[38;5;250m \u001B[39m\u001B[38;5;30m3\u001B[39m)));\n",
      "\u001B[38;5;250m  \u001B[39massert(((\u001B[38;5;37mvoid\u001B[39m)\u001B[38;5;130m\"\u001B[39m\u001B[38;5;130mThe 2-th argument should be TensorPointerType(tensor(float32, [1024, 1024]))\u001B[39m\u001B[38;5;130m\"\u001B[39m,\u001B[38;5;250m \u001B[39m(arg_types[\u001B[38;5;30m2\u001B[39m]\u001B[38;5;250m \u001B[39m==\u001B[38;5;250m \u001B[39m\u001B[38;5;30m3\u001B[39m)));\n",
      "\u001B[38;5;250m  \u001B[39mhidet_kernel<<<\u001B[38;5;37mdim3\u001B[39m(\u001B[38;5;30m32\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;30m1\u001B[39m),\u001B[38;5;250m \u001B[39m\u001B[38;5;37mdim3\u001B[39m(\u001B[38;5;30m32\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;30m1\u001B[39m),\u001B[38;5;250m \u001B[39m\u001B[38;5;30m0\u001B[39m,\u001B[38;5;250m \u001B[39m(cudaStream_t)get_cuda_stream()>>>(((\u001B[38;5;37mfloat\u001B[39m*)(args[\u001B[38;5;30m0\u001B[39m])),\u001B[38;5;250m \u001B[39m((\u001B[38;5;37mfloat\u001B[39m*)(args[\u001B[38;5;30m1\u001B[39m])),\u001B[38;5;250m \u001B[39m((\u001B[38;5;37mfloat\u001B[39m*)(args[\u001B[38;5;30m2\u001B[39m])));\n",
      "}\n",
      "\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.testing\n",
    "import hidet\n",
    "\n",
    "\n",
    "def matmul_func(m_size, n_size, k_size):\n",
    "    from hidet.lang import attr, f32, tensor\n",
    "    from hidet.lang import spatial, repeat\n",
    "    from hidet.lang.cuda import threadIdx, blockIdx, blockDim, syncthreads\n",
    "    from hidet.transforms.tools import add_packed_func\n",
    "\n",
    "    def ceil_div(a, b):\n",
    "        return (a + b - 1) // b\n",
    "\n",
    "    tm, tn, tk = 32, 32, 128\n",
    "\n",
    "    assert tk % tm == 0\n",
    "    assert tk % tn == 0\n",
    "    # make sure the matrix size is divisible by the tile size\n",
    "    assert m_size % tm == 0 and n_size % tn == 0 and k_size % tk == 0\n",
    "\n",
    "    with hidet.script_module() as script_module:\n",
    "\n",
    "        @hidet.script\n",
    "        def kernel(\n",
    "            a: f32[m_size, k_size],\n",
    "            b: f32[k_size, n_size],\n",
    "            c: f32[m_size, n_size]\n",
    "        ):\n",
    "            attr.func_kind = 'cuda_kernel'\n",
    "            attr.cuda_block_dim = tn, tm\n",
    "            attr.cuda_grid_dim = n_size / tn, m_size / tm\n",
    "\n",
    "            smem_a = tensor(scope='shared', dtype='float32', shape=[tm, tk])\n",
    "            smem_b = tensor(scope='shared', dtype='float32', shape=[tk, tn])\n",
    "\n",
    "            acc = f32(0.0)\n",
    "            for k_tile in range(k_size / tk):\n",
    "                gmem_a = a[blockIdx.y * tm: , k_tile * tk: ]\n",
    "                gmem_b = b[k_tile * tk: , blockIdx.x * tn: ]\n",
    "\n",
    "                # load data from global memory to shared memory\n",
    "                tid = threadIdx.x + threadIdx.y * blockDim.y\n",
    "\n",
    "                for i, k in repeat(1, tk / tn).spatial(tm, tn).on(tid):\n",
    "                    smem_a[i, k] = gmem_a[i, k]\n",
    "\n",
    "                for k, j in repeat(tk / tm, 1).spatial(tm, tn).on(tid):\n",
    "                    smem_b[k, j] = gmem_b[k, j]\n",
    "\n",
    "                syncthreads()\n",
    "\n",
    "                # compute\n",
    "                for k in range(tk):\n",
    "                    acc += smem_a[threadIdx.y, k] * smem_b[k, threadIdx.x]\n",
    "                syncthreads()\n",
    "\n",
    "            # write result\n",
    "            gi, gj = blockIdx.y * tm + threadIdx.y, blockIdx.x * tn + threadIdx.x\n",
    "            c[gi, gj] = acc\n",
    "\n",
    "    ir_module = script_module.ir_module()\n",
    "    add_packed_func(ir_module, func=kernel, pack_func_name='matmul')\n",
    "    return hidet.driver.build_ir_module(ir_module, func_name='matmul')\n",
    "\n",
    "\n",
    "m_size, n_size, k_size = 1024, 1024, 1024\n",
    "matmul = matmul_func(m_size, n_size, k_size)\n",
    "print(matmul.source(color=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctness: Pass\n",
      "    Latency: 0.69 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = hidet.randn([m_size, k_size]).cuda()\n",
    "b = hidet.randn([k_size, n_size]).cuda()\n",
    "c = hidet.empty([m_size, n_size]).cuda()\n",
    "matmul(a, b, c)\n",
    "\n",
    "np_a = a.cpu().numpy()\n",
    "np_b = b.cpu().numpy()\n",
    "np_c = np.matmul(np_a, np_b)\n",
    "\n",
    "numpy.testing.assert_allclose(c.cpu().numpy(), np_c, rtol=1e-4, atol=1e-4)\n",
    "print('Correctness: Pass')\n",
    "\n",
    "latency = hidet.utils.benchmark_func(lambda: matmul(a, b, c), number=20, repeat=20)\n",
    "print('    Latency: {:.2f} ms'.format(latency))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
