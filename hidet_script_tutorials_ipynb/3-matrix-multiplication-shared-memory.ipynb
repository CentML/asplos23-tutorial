{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;64m#\u001B[39m\u001B[38;5;64minclude\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;248;03m<stdint.h>\u001B[39;00m\n",
      "\u001B[38;5;64m#\u001B[39m\u001B[38;5;64minclude\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;248;03m<cuda_fp16.h>\u001B[39;00m\n",
      "\u001B[38;5;64m#\u001B[39m\u001B[38;5;64minclude\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;248;03m<cuda_bf16.h>\u001B[39;00m\n",
      "\u001B[38;5;64m#\u001B[39m\u001B[38;5;64minclude\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;248;03m<hidet/runtime/cuda_context.h>\u001B[39;00m\n",
      "\u001B[38;5;64m#\u001B[39m\u001B[38;5;64minclude\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;248;03m<hidet/runtime/cpu_context.h>\u001B[39;00m\n",
      "\u001B[38;5;19mtypedef\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;37mfloat\u001B[39m\u001B[38;5;250m \u001B[39mtfloat32_t;\n",
      "\u001B[38;5;64m#\u001B[39m\u001B[38;5;64mdefine __float_to_tf32(x) (x)\u001B[39m\n",
      "\u001B[38;5;19mextern\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;130m\"\u001B[39m\u001B[38;5;130mC\u001B[39m\u001B[38;5;130m\"\u001B[39m\u001B[38;5;250m \u001B[39m{\n",
      "\n",
      "\u001B[38;5;19m__global__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;37mvoid\u001B[39m\u001B[38;5;250m \u001B[39m__launch_bounds__(\u001B[38;5;30m1024\u001B[39m)\u001B[38;5;250m \u001B[39mhidet_kernel(\u001B[38;5;37mfloat\u001B[39m\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;37m__restrict__\u001B[39m\u001B[38;5;250m \u001B[39ma,\u001B[38;5;250m \u001B[39m\u001B[38;5;37mfloat\u001B[39m\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;37m__restrict__\u001B[39m\u001B[38;5;250m \u001B[39mb,\u001B[38;5;250m \u001B[39m\u001B[38;5;37mfloat\u001B[39m\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;37m__restrict__\u001B[39m\u001B[38;5;250m \u001B[39mc)\u001B[38;5;250m \u001B[39m{\n",
      "\u001B[38;5;250m  \u001B[39m\u001B[38;5;37m__shared__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;37mfloat\u001B[39m\u001B[38;5;250m \u001B[39msmem_a[\u001B[38;5;30m4096\u001B[39m];\n",
      "\u001B[38;5;250m  \u001B[39m\u001B[38;5;37m__shared__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;37mfloat\u001B[39m\u001B[38;5;250m \u001B[39msmem_b[\u001B[38;5;30m4096\u001B[39m];\n",
      "\u001B[38;5;250m  \u001B[39m\u001B[38;5;37mfloat\u001B[39m\u001B[38;5;250m \u001B[39macc\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m\u001B[38;5;30m0.0f\u001B[39m;\n",
      "\u001B[38;5;250m  \u001B[39m\u001B[38;5;19mfor\u001B[39m\u001B[38;5;250m \u001B[39m(\u001B[38;5;37mint32_t\u001B[39m\u001B[38;5;250m \u001B[39mk_tile\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m\u001B[38;5;30m0\u001B[39m;\u001B[38;5;250m \u001B[39m(k_tile\u001B[38;5;250m \u001B[39m<\u001B[38;5;250m \u001B[39m\u001B[38;5;30m8\u001B[39m);\u001B[38;5;250m \u001B[39mk_tile\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m(k_tile\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m\u001B[38;5;30m1\u001B[39m))\u001B[38;5;250m \u001B[39m{\n",
      "\u001B[38;5;250m    \u001B[39m\u001B[38;5;37mint32_t\u001B[39m\u001B[38;5;250m \u001B[39mtid\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m((\u001B[38;5;37mint\u001B[39m)\u001B[38;5;37mthreadIdx\u001B[39m.x\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m((\u001B[38;5;37mint\u001B[39m)\u001B[38;5;37mthreadIdx\u001B[39m.y\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m));\n",
      "\u001B[38;5;250m    \u001B[39m\u001B[38;5;19mfor\u001B[39m\u001B[38;5;250m \u001B[39m(\u001B[38;5;37mint32_t\u001B[39m\u001B[38;5;250m \u001B[39mi\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m\u001B[38;5;30m0\u001B[39m;\u001B[38;5;250m \u001B[39m(i\u001B[38;5;250m \u001B[39m<\u001B[38;5;250m \u001B[39m\u001B[38;5;30m4\u001B[39m);\u001B[38;5;250m \u001B[39mi\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m(i\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m\u001B[38;5;30m1\u001B[39m))\u001B[38;5;250m \u001B[39m{\n",
      "\u001B[38;5;250m      \u001B[39msmem_a[(((tid\u001B[38;5;250m \u001B[39m/\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m128\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m((i\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(tid\u001B[38;5;250m \u001B[39m%\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)))]\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39ma[(((((\u001B[38;5;37mint\u001B[39m)\u001B[38;5;37mblockIdx\u001B[39m.y\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(tid\u001B[38;5;250m \u001B[39m/\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m))\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m1024\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m((k_tile\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m128\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m((i\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(tid\u001B[38;5;250m \u001B[39m%\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m))))];\n",
      "\u001B[38;5;250m    \u001B[39m}\u001B[38;5;250m \u001B[39m\n",
      "\u001B[38;5;250m    \u001B[39m\u001B[38;5;19mfor\u001B[39m\u001B[38;5;250m \u001B[39m(\u001B[38;5;37mint32_t\u001B[39m\u001B[38;5;250m \u001B[39mi_1\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m\u001B[38;5;30m0\u001B[39m;\u001B[38;5;250m \u001B[39m(i_1\u001B[38;5;250m \u001B[39m<\u001B[38;5;250m \u001B[39m\u001B[38;5;30m4\u001B[39m);\u001B[38;5;250m \u001B[39mi_1\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m(i_1\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m\u001B[38;5;30m1\u001B[39m))\u001B[38;5;250m \u001B[39m{\n",
      "\u001B[38;5;250m      \u001B[39msmem_b[((((i_1\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(tid\u001B[38;5;250m \u001B[39m/\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m))\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(tid\u001B[38;5;250m \u001B[39m%\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m))]\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39mb[((((k_tile\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m128\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m((i_1\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(tid\u001B[38;5;250m \u001B[39m/\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)))\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m1024\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(((\u001B[38;5;37mint\u001B[39m)\u001B[38;5;37mblockIdx\u001B[39m.x\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(tid\u001B[38;5;250m \u001B[39m%\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)))];\n",
      "\u001B[38;5;250m    \u001B[39m}\u001B[38;5;250m \u001B[39m\n",
      "\u001B[38;5;250m    \u001B[39m\u001B[38;5;34m__syncthreads\u001B[39m();\n",
      "\u001B[38;5;250m    \u001B[39m\u001B[38;5;19mfor\u001B[39m\u001B[38;5;250m \u001B[39m(\u001B[38;5;37mint32_t\u001B[39m\u001B[38;5;250m \u001B[39mk\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m\u001B[38;5;30m0\u001B[39m;\u001B[38;5;250m \u001B[39m(k\u001B[38;5;250m \u001B[39m<\u001B[38;5;250m \u001B[39m\u001B[38;5;30m128\u001B[39m);\u001B[38;5;250m \u001B[39mk\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m(k\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m\u001B[38;5;30m1\u001B[39m))\u001B[38;5;250m \u001B[39m{\n",
      "\u001B[38;5;250m      \u001B[39macc\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39m(acc\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(smem_a[(((\u001B[38;5;37mint\u001B[39m)\u001B[38;5;37mthreadIdx\u001B[39m.y\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m128\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39mk)]\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39msmem_b[((k\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(\u001B[38;5;37mint\u001B[39m)\u001B[38;5;37mthreadIdx\u001B[39m.x)]));\n",
      "\u001B[38;5;250m    \u001B[39m}\u001B[38;5;250m \u001B[39m\n",
      "\u001B[38;5;250m    \u001B[39m\u001B[38;5;34m__syncthreads\u001B[39m();\n",
      "\u001B[38;5;250m  \u001B[39m}\u001B[38;5;250m \u001B[39m\n",
      "\u001B[38;5;250m  \u001B[39mc[(((((\u001B[38;5;37mint\u001B[39m)\u001B[38;5;37mblockIdx\u001B[39m.y\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(\u001B[38;5;37mint\u001B[39m)\u001B[38;5;37mthreadIdx\u001B[39m.y)\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m1024\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(((\u001B[38;5;37mint\u001B[39m)\u001B[38;5;37mblockIdx\u001B[39m.x\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m(\u001B[38;5;37mint\u001B[39m)\u001B[38;5;37mthreadIdx\u001B[39m.x))]\u001B[38;5;250m \u001B[39m=\u001B[38;5;250m \u001B[39macc;\n",
      "}\n",
      "\n",
      "\u001B[38;5;19m__host__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;37mvoid\u001B[39m\u001B[38;5;250m \u001B[39mhidet_matmul(\u001B[38;5;37mint32_t\u001B[39m\u001B[38;5;250m \u001B[39mnum_args,\u001B[38;5;250m \u001B[39m\u001B[38;5;37mint32_t\u001B[39m\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;37m__restrict__\u001B[39m\u001B[38;5;250m \u001B[39marg_types,\u001B[38;5;250m \u001B[39m\u001B[38;5;37mvoid\u001B[39m*\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;37m__restrict__\u001B[39m\u001B[38;5;250m \u001B[39margs)\u001B[38;5;250m \u001B[39m{\n",
      "\u001B[38;5;250m  \u001B[39massert(((\u001B[38;5;37mvoid\u001B[39m)\u001B[38;5;130m\"\u001B[39m\u001B[38;5;130mExpect 3 arguments\u001B[39m\u001B[38;5;130m\"\u001B[39m,\u001B[38;5;250m \u001B[39m(num_args\u001B[38;5;250m \u001B[39m==\u001B[38;5;250m \u001B[39m\u001B[38;5;30m3\u001B[39m)));\n",
      "\u001B[38;5;250m  \u001B[39massert(((\u001B[38;5;37mvoid\u001B[39m)\u001B[38;5;130m\"\u001B[39m\u001B[38;5;130mThe 0-th argument should be TensorPointerType(tensor(float32, [1024, 1024]))\u001B[39m\u001B[38;5;130m\"\u001B[39m,\u001B[38;5;250m \u001B[39m(arg_types[\u001B[38;5;30m0\u001B[39m]\u001B[38;5;250m \u001B[39m==\u001B[38;5;250m \u001B[39m\u001B[38;5;30m3\u001B[39m)));\n",
      "\u001B[38;5;250m  \u001B[39massert(((\u001B[38;5;37mvoid\u001B[39m)\u001B[38;5;130m\"\u001B[39m\u001B[38;5;130mThe 1-th argument should be TensorPointerType(tensor(float32, [1024, 1024]))\u001B[39m\u001B[38;5;130m\"\u001B[39m,\u001B[38;5;250m \u001B[39m(arg_types[\u001B[38;5;30m1\u001B[39m]\u001B[38;5;250m \u001B[39m==\u001B[38;5;250m \u001B[39m\u001B[38;5;30m3\u001B[39m)));\n",
      "\u001B[38;5;250m  \u001B[39massert(((\u001B[38;5;37mvoid\u001B[39m)\u001B[38;5;130m\"\u001B[39m\u001B[38;5;130mThe 2-th argument should be TensorPointerType(tensor(float32, [1024, 1024]))\u001B[39m\u001B[38;5;130m\"\u001B[39m,\u001B[38;5;250m \u001B[39m(arg_types[\u001B[38;5;30m2\u001B[39m]\u001B[38;5;250m \u001B[39m==\u001B[38;5;250m \u001B[39m\u001B[38;5;30m3\u001B[39m)));\n",
      "\u001B[38;5;250m  \u001B[39mhidet_kernel<<<\u001B[38;5;37mdim3\u001B[39m(\u001B[38;5;30m32\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;30m1\u001B[39m),\u001B[38;5;250m \u001B[39m\u001B[38;5;37mdim3\u001B[39m(\u001B[38;5;30m32\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;30m32\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;30m1\u001B[39m),\u001B[38;5;250m \u001B[39m\u001B[38;5;30m0\u001B[39m,\u001B[38;5;250m \u001B[39m(cudaStream_t)get_cuda_stream()>>>(((\u001B[38;5;37mfloat\u001B[39m*)(args[\u001B[38;5;30m0\u001B[39m])),\u001B[38;5;250m \u001B[39m((\u001B[38;5;37mfloat\u001B[39m*)(args[\u001B[38;5;30m1\u001B[39m])),\u001B[38;5;250m \u001B[39m((\u001B[38;5;37mfloat\u001B[39m*)(args[\u001B[38;5;30m2\u001B[39m])));\n",
      "}\n",
      "\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.testing\n",
    "import hidet\n",
    "\n",
    "\n",
    "def matmul_func(m_size, n_size, k_size):\n",
    "    from hidet.lang import attr, f32, tensor\n",
    "    from hidet.lang import spatial, repeat\n",
    "    from hidet.lang.cuda import threadIdx, blockIdx, blockDim, syncthreads\n",
    "    from hidet.transforms.tools import add_packed_func\n",
    "\n",
    "    def ceil_div(a, b):\n",
    "        return (a + b - 1) // b\n",
    "\n",
    "    block_dim_m, block_dim_n = 32, 32\n",
    "    k_tile_size = 128    # choices: 32, 64, 96, 128\n",
    "    grid_dim_m, grid_dim_n = ceil_div(m_size, block_dim_m), ceil_div(n_size, block_dim_n)\n",
    "\n",
    "    assert k_tile_size % block_dim_m == 0\n",
    "    assert k_tile_size % block_dim_n == 0\n",
    "\n",
    "    with hidet.script_module() as script_module:\n",
    "\n",
    "        @hidet.script\n",
    "        def kernel(\n",
    "            a: f32[m_size, k_size],\n",
    "            b: f32[k_size, n_size],\n",
    "            c: f32[m_size, n_size]\n",
    "        ):\n",
    "            attr.func_kind = 'cuda_kernel'\n",
    "            attr.cuda_block_dim = block_dim_n, block_dim_m\n",
    "            attr.cuda_grid_dim = grid_dim_n, grid_dim_m\n",
    "\n",
    "            smem_a = tensor(scope='shared', dtype='float32', shape=[block_dim_m, k_tile_size])\n",
    "            smem_b = tensor(scope='shared', dtype='float32', shape=[k_tile_size, block_dim_n])\n",
    "\n",
    "            k_tiles = ceil_div(k_size, k_tile_size)\n",
    "            acc = f32(0.0)\n",
    "            for k_tile in range(k_tiles):\n",
    "                # load data from global memory to shared memory\n",
    "                tid = threadIdx.x + threadIdx.y * blockDim.y\n",
    "                for i, k in repeat(1, k_tile_size / block_dim_n).spatial(block_dim_m, block_dim_n).on(tid):\n",
    "                    gi, gk = blockIdx.y * block_dim_m + i, k_tile * k_tile_size + k\n",
    "                    smem_a[i, k] = a[gi, gk] if gi < m_size and gk < k_size else f32(0.0)\n",
    "                for k, j in repeat(k_tile_size / block_dim_m, 1).spatial(block_dim_m, block_dim_n).on(tid):\n",
    "                    gk, gj = k_tile * k_tile_size + k, blockIdx.x * block_dim_n + j\n",
    "                    smem_b[k, j] = b[gk, gj] if gk < k_size and gj < n_size else f32(0.0)\n",
    "                syncthreads()\n",
    "\n",
    "                # compute\n",
    "                for k in range(k_tile_size):\n",
    "                    acc += smem_a[threadIdx.y, k] * smem_b[k, threadIdx.x]\n",
    "                syncthreads()\n",
    "\n",
    "            # write result\n",
    "            gi, gj = blockIdx.y * block_dim_m + threadIdx.y, blockIdx.x * block_dim_n + threadIdx.x\n",
    "            if gi < m_size and gj < n_size:\n",
    "                c[gi, gj] = acc\n",
    "\n",
    "    ir_module = script_module.ir_module()\n",
    "    add_packed_func(ir_module, func=kernel, pack_func_name='matmul')\n",
    "    return hidet.driver.build_ir_module(ir_module, func_name='matmul')\n",
    "\n",
    "\n",
    "m_size, n_size, k_size = 1024, 1024, 1024\n",
    "matmul = matmul_func(m_size, n_size, k_size)\n",
    "print(matmul.source(color=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctness: Pass\n",
      "    Latency: 0.70 ms\n"
     ]
    }
   ],
   "source": [
    "a = hidet.randn([m_size, k_size]).cuda()\n",
    "b = hidet.randn([k_size, n_size]).cuda()\n",
    "c = hidet.empty([m_size, n_size]).cuda()\n",
    "matmul(a, b, c)\n",
    "\n",
    "np_a = a.cpu().numpy()\n",
    "np_b = b.cpu().numpy()\n",
    "np_c = np.matmul(np_a, np_b)\n",
    "\n",
    "numpy.testing.assert_allclose(c.cpu().numpy(), np_c, rtol=1e-4, atol=1e-4)\n",
    "print('Correctness: Pass')\n",
    "latency = hidet.utils.benchmark_func(lambda: matmul(a, b, c))\n",
    "print('    Latency: {:.2f} ms'.format(latency))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
