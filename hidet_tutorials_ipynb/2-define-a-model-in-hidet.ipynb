{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a model in Hidet\n",
    "On top of running PyTorch and ONNX models through their respective frontends in Hidet, you may also define your own model with Hidet and run it. In this tutorial, we will walk through a simple example of defining, optimizing, and running a small model with Hidet.\n",
    "\n",
    "To run the tutorial, you need to install Hidet and jupyter notebook:\n",
    "```bash\n",
    "$ pip install hidet jupyter\n",
    "```\n",
    "\n",
    "Then, you can launch the jupyter notebook by running `jupyter notebook`\n",
    "```bash\n",
    "$ jupyter notebook\n",
    "```\n",
    "\n",
    "and open this tutorial in the browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hidet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "Defining a Hidet model is similar to defining a PyTorch model. Instead of the PyTorch operators, we will use Hidet operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv_relu(x, out_channels, kernel, stride, padding):\n",
    "    w = hidet.randn(shape=[out_channels, x.shape[1], kernel, kernel]).cuda()\n",
    "    b = hidet.randn(shape=[1, out_channels, 1, 1]).cuda()\n",
    "    x = hidet.ops.conv_pad(x, pads=padding)\n",
    "    x = hidet.ops.conv2d(x, w, stride=stride) + b\n",
    "    x = hidet.ops.relu(x)\n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a simple model consisting of a convolution layer and a ReLU layer. Inside the model, we first randomly generate the weight `w` and bias `b` as constants. We use `.cuda()` to move them to the GPU as we later wish to run the model using GPU. Then we get the result by padding the input `x`, and applying the `conv2d` and `relu` layers. For a list of other operators, please refer to the [Hidet Python API](https://docs.hidet.org/stable/python_api/ops/index.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imperatively run the model\n",
    "\n",
    "The model can be directly run by feeding in an input tensor and the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = hidet.randn([1, 3, 224, 224]).cuda()\n",
    "out = conv_relu(img, 64, 7, 2, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomly generate an input `img`. The output tensor of the model is `out`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace the model and run\n",
    "A more efficient way to run the model is to first trace the execution and get the static computation graph of the deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(x: float32[1, 3, 224, 224]){\n",
      "  c = Constant(float32[64, 3, 7, 7])\n",
      "  c_1 = Constant(float32[1, 64, 1, 1])\n",
      "  x_1: float32[1, 3, 230, 230] = Pad(x, pads=[0, 0, 3, 3, 0, 0, 3, 3], mode=\"constant\", value=0.0)  \n",
      "  x_2: float32[1, 64, 112, 112] = Conv2d(x_1, c, stride=[2, 2], groups=1, dilations=(1, 1))  \n",
      "  x_3: float32[1, 64, 112, 112] = Add(x_2, c_1)  \n",
      "  x_4: float32[1, 64, 112, 112] = Relu(x_3)  \n",
      "  return x_4\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "img_sym = hidet.symbol([1, 3, 224, 224]).cuda()\n",
    "out_sym = conv_relu(img_sym, 64, 7, 2, 3)\n",
    "graph = hidet.trace_from(out_sym, inputs=[img_sym])\n",
    "print(graph)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the input `img_sym` as a symbol tensor. We get the symbol output by running the `conv_relu()` model with the symbol input. `out_sym` is a symbol tensor that contains all the information of how it is derived. Then we can use `hidet.trace_from()` to create the static computation graph from the symbol output. \n",
    "\n",
    "`graph` is an instance of `hidet.graph.FlowGraph`, which is Hidet's representation of a computation graph and also the basic unit of graph-level optimizations. You can print `graph` to get its textual definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidet: 0.132 ms\n"
     ]
    }
   ],
   "source": [
    "from hidet.utils import benchmark_func\n",
    "cuda_graph = graph.cuda_graph()\n",
    "img = hidet.randn([1, 3, 224, 224]).cuda()\n",
    "(out,) = cuda_graph.run([img])\n",
    "print('Hidet: {:.3f} ms'.format(benchmark_func(lambda: cuda_graph.run())))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `cuda_graph()` method of a `FlowGraph` to create a `CudaGraph`. Cuda Graph is a more effcient way to submit workloads to NVIDIA GPUs as it eliminates framework-side overhead.\n",
    "\n",
    "We randomly generate an input tensor `img` and get the output tensor `out` by calling `run()` with the cuda graph and input. We also test the latency of our model.\n",
    "### Optimize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling cuda task \u001b[92mrearrange(x=float32[1, 64, 3, 7, 7])\u001b[0m...\n",
      "Compiling cuda task \u001b[92mbarrier(x=float32[1, 230, 230, 3]) (2 fused)\u001b[0m...\n",
      "Compiling cuda task \u001b[92mbatch_matmul(a=float32[1, 12544, 147], b=float32[1, 147, 64], batch_size=1, m_size=12544, n_size=64, k_size=147, mma=simt) (5 fused)\u001b[0m...\n",
      "Compiling: 100%|██████████████████████████████| 214/214 [02:19<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch build 214 modules within 139.708 seconds, on average 0.7 seconds per module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Benchmarking: 100%|██████████████████████████| 214/214 [00:01<00:00, 110.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidet optimized: 0.036 ms\n"
     ]
    }
   ],
   "source": [
    "hidet.option.search_space(2)\n",
    "with hidet.graph.PassContext() as ctx:\n",
    "    ctx.save_graph_instrument('./outs/graphs')\n",
    "    graph_opt = hidet.graph.optimize(graph)\n",
    "    cuda_graph_opt = graph_opt.cuda_graph()\n",
    "    print('Hidet optimized: {:.3f} ms'.format(benchmark_func(lambda: cuda_graph_opt.run())))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimize the model, we set the level of operator schedule space to 2 with `hidet.option.search_space()`. The search space level can be : 0, 1, and 2. By default, the search space level is 0, which means no kernel tuning. The higher the level, the better performance but longer compilation time. The above code may take a few minutes to run, depending on the machine.\n",
    "\n",
    "We also perform graph level optimizations with `hidet.graph.optimize()` and save intermiediate graphs with `save_graph_instrument()`. We run the benchmark again to see that the resulting optimized model runs faster than the previous unoptimized version."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
