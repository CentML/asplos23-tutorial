{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook\n",
    "In this notebook, we will show you how we profile and optimize a canonical computer vision training instance: *ResNet50 + CIFAR100*. In the end, we would achive near 10x speedup from the baseline.\n",
    "\n",
    "The notebook is brokendown into \"Optimization stages\", were we incrementally permute our training pipeline to perform system-level optimization on different parts\n",
    "of the training logic. \n",
    "\n",
    "Please follow along this notebook, follow the comments that show ########## Optimization X ################### for code changes in each optimization stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/user/venv2/lib/python3.10/site-packages (4.65.0)\n",
      "Requirement already satisfied: torch in /home/user/venv2/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: torchvision in /home/user/venv2/lib/python3.10/site-packages (0.15.1)\n",
      "Requirement already satisfied: torch_tb_profiler in /home/user/venv2/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: tensorboard==2.12.0 in /home/user/venv2/lib/python3.10/site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorboard-plugin-profile==2.11.2 in /home/user/venv2/lib/python3.10/site-packages (2.11.2)\n",
      "Requirement already satisfied: tensorflow==2.12.0 in /home/user/venv2/lib/python3.10/site-packages (2.12.0)\n",
      "Requirement already satisfied: protobuf==3.20.3 in /home/user/venv2/lib/python3.10/site-packages (3.20.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/user/venv2/lib/python3.10/site-packages (from tensorboard==2.12.0) (1.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/user/venv2/lib/python3.10/site-packages (from tensorboard==2.12.0) (2.28.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/user/venv2/lib/python3.10/site-packages (from tensorboard==2.12.0) (0.37.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/user/venv2/lib/python3.10/site-packages (from tensorboard==2.12.0) (1.23.5)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/user/venv2/lib/python3.10/site-packages (from tensorboard==2.12.0) (2.2.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/user/venv2/lib/python3.10/site-packages (from tensorboard==2.12.0) (59.6.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/user/venv2/lib/python3.10/site-packages (from tensorboard==2.12.0) (1.51.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/user/venv2/lib/python3.10/site-packages (from tensorboard==2.12.0) (0.7.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/user/venv2/lib/python3.10/site-packages (from tensorboard==2.12.0) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/user/venv2/lib/python3.10/site-packages (from tensorboard==2.12.0) (3.4.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/user/venv2/lib/python3.10/site-packages (from tensorboard==2.12.0) (2.16.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/user/venv2/lib/python3.10/site-packages (from tensorboard==2.12.0) (0.4.6)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/user/venv2/lib/python3.10/site-packages (from tensorboard-plugin-profile==2.11.2) (1.16.0)\n",
      "Requirement already satisfied: gviz-api>=1.9.0 in /home/user/venv2/lib/python3.10/site-packages (from tensorboard-plugin-profile==2.11.2) (1.10.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/user/venv2/lib/python3.10/site-packages (from tensorflow==2.12.0) (1.14.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/user/venv2/lib/python3.10/site-packages (from tensorflow==2.12.0) (3.8.0)\n",
      "Requirement already satisfied: packaging in /home/user/venv2/lib/python3.10/site-packages (from tensorflow==2.12.0) (23.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/user/venv2/lib/python3.10/site-packages (from tensorflow==2.12.0) (2.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/user/venv2/lib/python3.10/site-packages (from tensorflow==2.12.0) (3.3.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /home/user/venv2/lib/python3.10/site-packages (from tensorflow==2.12.0) (2.12.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/user/venv2/lib/python3.10/site-packages (from tensorflow==2.12.0) (23.3.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /home/user/venv2/lib/python3.10/site-packages (from tensorflow==2.12.0) (2.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/user/venv2/lib/python3.10/site-packages (from tensorflow==2.12.0) (16.0.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/user/venv2/lib/python3.10/site-packages (from tensorflow==2.12.0) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/user/venv2/lib/python3.10/site-packages (from tensorflow==2.12.0) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/user/venv2/lib/python3.10/site-packages (from tensorflow==2.12.0) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/user/venv2/lib/python3.10/site-packages (from tensorflow==2.12.0) (4.5.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /home/user/venv2/lib/python3.10/site-packages (from tensorflow==2.12.0) (0.4.6)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/user/venv2/lib/python3.10/site-packages (from tensorflow==2.12.0) (0.31.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/user/venv2/lib/python3.10/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: sympy in /home/user/venv2/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in /home/user/venv2/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/user/venv2/lib/python3.10/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/user/venv2/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/user/venv2/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: networkx in /home/user/venv2/lib/python3.10/site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/user/venv2/lib/python3.10/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/user/venv2/lib/python3.10/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/user/venv2/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/user/venv2/lib/python3.10/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: filelock in /home/user/venv2/lib/python3.10/site-packages (from torch) (3.10.4)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/user/venv2/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/user/venv2/lib/python3.10/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/user/venv2/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/user/venv2/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: cmake in /home/user/venv2/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.26.1)\n",
      "Requirement already satisfied: lit in /home/user/venv2/lib/python3.10/site-packages (from triton==2.0.0->torch) (16.0.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/user/venv2/lib/python3.10/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /home/user/venv2/lib/python3.10/site-packages (from torch_tb_profiler) (1.5.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/user/venv2/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.12.0) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/user/venv2/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.12.0) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/user/venv2/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.12.0) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/user/venv2/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.12.0) (1.3.1)\n",
      "Requirement already satisfied: scipy>=1.5 in /home/user/venv2/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/user/venv2/lib/python3.10/site-packages (from pandas>=1.0.0->torch_tb_profiler) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/user/venv2/lib/python3.10/site-packages (from pandas>=1.0.0->torch_tb_profiler) (2023.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/venv2/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard==2.12.0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/venv2/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard==2.12.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/user/venv2/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard==2.12.0) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/venv2/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard==2.12.0) (3.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/user/venv2/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard==2.12.0) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/user/venv2/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/user/venv2/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.12.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/user/venv2/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.12.0) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "# Install profiler dependencies\n",
    "!pip install tqdm torch torchvision torch_tb_profiler tensorboard==2.12.0 tensorboard-plugin-profile==2.11.2 tensorflow==2.12.0 protobuf==3.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5kcB0zwMCdLA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXYuWN4_gRh4"
   },
   "source": [
    "## Model\n",
    "We include a basic implementation of ResNet50 based on torchvision's implementation, but removes \n",
    "the extra boilerplate code for better readability.\n",
    "Please navigate to `model.py` to check model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DGfkrKemCl50"
   },
   "outputs": [],
   "source": [
    "from model import ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mef7QUjNgkcf"
   },
   "source": [
    "## Data\n",
    "For the notebook to run in a reasonable time, we pick CIFAR100 as our dataloader, which is an image dataset with 3x32x32 images from 100 classes.\n",
    "\n",
    "We select a few data-augmentation techniques, they include:\n",
    "* Crop\n",
    "* Horizontal Flip\n",
    "* Gaussian blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jSe003_Sglv3"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def get_loaders(train_bs, val_bs):\n",
    "\n",
    "  transform_train = transforms.Compose([\n",
    "      transforms.RandomCrop(32, padding=4),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.GaussianBlur(3),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  transform_test = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  trainset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=True, download=True, transform=transform_train)\n",
    "  trainloader = torch.utils.data.DataLoader(\n",
    "      trainset, batch_size=train_bs, shuffle=True)\n",
    "\n",
    "  testset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=False, download=True, transform=transform_test)\n",
    "  testloader = torch.utils.data.DataLoader(\n",
    "      testset, batch_size=val_bs, shuffle=False)\n",
    "  \n",
    "  return trainloader, testloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SV_reOX8gU9X"
   },
   "source": [
    "## Training\n",
    "This training loop below is a standard supervised image classification training procedure as suggested by PyTorch examples.\n",
    "Please skim over this quickly as the details (such as logging, and metrics reporting) don't matter as much for our workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nB0takEVh9E2"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from tqdm.notebook import  tqdm\n",
    "import sys, os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tcDAxY3AjX1Y"
   },
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "end_epoch = 2\n",
    "lr = 0.1\n",
    "best_acc = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "USprdxU8jhOI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0VnQ4n4zEJ2M"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, epoch, trainloader, prof=None):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with tqdm(total=len(trainloader), file=sys.stdout, ) as pbar:\n",
    "      for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "          inputs, targets = inputs.to(device), targets.to(device)\n",
    "          optimizer.zero_grad()\n",
    "          outputs = model(inputs)\n",
    "          loss = criterion(outputs, targets)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          train_loss += loss.item()\n",
    "          _, predicted = outputs.max(-1)\n",
    "          total += targets.size(0)\n",
    "          correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "          pbar.set_description('[%3d]/[%3d]Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                      % (batch_idx, len(trainloader), train_loss/(batch_idx+1), \n",
    "                          100.*correct/total, correct, total),)\n",
    "          pbar.update(1)\n",
    "          \n",
    "          if prof is not None:\n",
    "            prof.step()\n",
    "            if batch_idx == 20:\n",
    "              return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, optimizer, epoch, testloader):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "      with tqdm(total=len(testloader), file=sys.stdout) as pbar:\n",
    "\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(-1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.set_description('[%3d]/[%3d]Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                         % (batch_idx, len(testloader), test_loss/(batch_idx+1), \n",
    "                            100.*correct/total, correct, total),)\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "The baseline simply runs the training loop for 2 epochs, and reports the training time for the second epoch (when things are more stable).\n",
    "\n",
    "We use `tqdm` to report training progression for each epoch, As it trains, you should notice the loss on the left of the progress bar to decrease, as well as the iteration time on the right of the progress bar.\n",
    "\n",
    "The expected runtime for this snippet is 160 (80*2) seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "id": "LxanaJZzEndq",
    "outputId": "015b9a5d-98fc-4379-83b0-bfe6f6fc73c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff002d6110649d39cd634f001006be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c0780477ca4ed5b94469f04b48e5e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872e95348458456d8cfeff9616589b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcaed0e4083e43cda215e0e626812210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for one epoch takes 80.675s\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader = get_loaders(128, 128)\n",
    "import torchvision\n",
    "model = ResNet50(num_classes=100).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model, optimizer, epoch, trainloader)\n",
    "    epoch_end_time = time.time()\n",
    "    \n",
    "    test(model, optimizer, epoch, valloader)\n",
    "    scheduler.step()\n",
    "    if epoch > 0:\n",
    "        print(\"Training for one epoch takes {:.3f}s\".format(epoch_end_time - epoch_start_time))\n",
    "\n",
    "baseline_time = epoch_end_time - epoch_start_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling with torch.profiler\n",
    "\n",
    "We choose to profile with the built-in PyTorch profiler for its ease of use. \n",
    "\n",
    "For more detailed profiling, you could also use `vtune` (for Intel CPU), `nsys` (for NVIDIA GPU), and\n",
    "other vendor-specific profiling tools. \n",
    "\n",
    "However, they require more careful installation and\n",
    "launching procedures, which we do not have the resources to cover here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712f64dad25f4548a53e0294eae89681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "STAGE:2023-03-25 18:58:30 21279:21279 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "[W CPUAllocator.cpp:235] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event\n",
      "STAGE:2023-03-25 18:58:30 21279:21279 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-03-25 18:58:30 21279:21279 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader = get_loaders(128, 128)\n",
    "\n",
    "model = ResNet50(num_classes=100).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=5e-4)\n",
    "\n",
    "with torch.profiler.profile(\n",
    "        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "        schedule=torch.profiler.schedule(skip_first=10, wait=5, warmup=1, active=1, repeat=1),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./profile/baseline'),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True\n",
    ") as prof:\n",
    "    train(model, optimizer, 0, trainloader, prof)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open profiled results\n",
    "\n",
    "* Inside the folder `asplos23-tutorial/project`, run `tensorboard --logdir profile --bind_all` to run TensorBoard.\n",
    "* Navigate to `<machine_ip>:6006`, then select `pytorch_profiler` from the dropdown menu.\n",
    "* On the left under `Views`, select `Trace` to view the execution trace. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization1: re-order augmentation \n",
    "The first optimization concerns with data-augmentation.\n",
    "While many augmentation techniques are insensitive to ordering (i.e. crop after blur is identical to blur after crop),\n",
    "the performance implications are significant.\n",
    "\n",
    "Instead of issuing `ToTensor` last, we issue `ToTensor` first in the data augmentation pipeline, this would allow\n",
    "subsequent operations to run with `Tensor` objects which have better hardware utilization due to its better implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(train_bs, val_bs,):\n",
    "\n",
    "  transform_train = transforms.Compose([\n",
    "    ####### OPTIMIZATION 1 #################\n",
    "      transforms.ToTensor(),\n",
    "    ####### OPTIMIZATION 1 #################\n",
    "      transforms.RandomCrop(32, padding=4),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.GaussianBlur(3),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  transform_test = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  trainset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=True, download=True, transform=transform_train)\n",
    "  trainloader = torch.utils.data.DataLoader(\n",
    "      trainset, batch_size=train_bs, shuffle=True)\n",
    "\n",
    "  testset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=False, download=True, transform=transform_test)\n",
    "  testloader = torch.utils.data.DataLoader(\n",
    "      testset, batch_size=val_bs, shuffle=False)\n",
    "  \n",
    "  return trainloader, testloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "s2KGJdWLpNpa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9635fa7c588f434a8f5a750b856c68ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6707435f89904478ba3d7f398c55d673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f73da7ac9442ae8fc8f338884796ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9b40f188f347d19d09ff6eb45bd228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for one epoch takes 62.920s\n",
      "Speedup over baseline: 1.28\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(num_classes=100).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "trainloader, valloader = get_loaders(128, 128)\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model, optimizer, epoch, trainloader)\n",
    "    epoch_end_time = time.time()\n",
    "    test(model, optimizer, epoch, valloader)\n",
    "    scheduler.step()\n",
    "    if epoch > 0:\n",
    "        print(\"Training for one epoch takes {:.3f}s\".format(epoch_end_time - epoch_start_time))\n",
    "        print(\"Speedup over baseline: {:.2f}\".format(baseline_time / (epoch_end_time - epoch_start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization 2: pin_memory, pre-fetching, and batch_size\n",
    "By default, PyTorch does not enable data pre-fetching or loading data with multiple CPUs.\n",
    "\n",
    "To enable this, we need to set the `num_workers` argument in the dataloader.\n",
    "For a single GPU training setup, the best number is `number of cpus - 1 on your machine (7 in this case)`.\n",
    "\n",
    "Similarly, for GPU tensors, `pin_memory=True` would allow CPU tensors to be directly created in the pinned memory region,\n",
    "which is then copied to the GPU. Otherwise, we would incur an extra CPU-CPU copy.\n",
    "\n",
    "Lastly, batch size should be increased to the maximum of what your algorithm allows (for convergence) and what your hardware\n",
    "allows (before getting out of memory) for the best GPU utilization due to increased parallelism and memory reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(train_bs, val_bs,):\n",
    "\n",
    "  transform_train = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.RandomCrop(32, padding=4),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.GaussianBlur(3),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  transform_test = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  trainset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=True, download=True, transform=transform_train)\n",
    "  trainloader = torch.utils.data.DataLoader(\n",
    "    ####### OPTIMIZATION 2.1 #################\n",
    "      trainset, batch_size=train_bs, shuffle=True,\n",
    "      pin_memory=True,\n",
    "      num_workers=7,\n",
    "    ####### OPTIMIZATION 2.1 #################\n",
    "  )\n",
    "\n",
    "  testset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=False, download=True, transform=transform_test)\n",
    "  testloader = torch.utils.data.DataLoader(\n",
    "    ####### OPTIMIZATION 2 #################\n",
    "      testset, batch_size=val_bs, shuffle=False,\n",
    "      pin_memory=True,\n",
    "      num_workers=7,\n",
    "    ####### OPTIMIZATION 2 #################\n",
    "  )\n",
    "  \n",
    "  return trainloader, testloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DS6-O6yj0QVY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3d2fb162534bc09a5f29b995e40d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22c2037d158416d81ba3ac11892669b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00deb6a10a00404c94265ef27cd67409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4165776e4e7440338deea5cab3488784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for one epoch takes 22.848s\n",
      "Speedup over baseline: 3.53\n"
     ]
    }
   ],
   "source": [
    "####### OPTIMIZATION 2.2 #################\n",
    "trainloader, valloader = get_loaders(256, 512)\n",
    "####### OPTIMIZATION 2.2 #################\n",
    "\n",
    "model = ResNet50(num_classes=100).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model, optimizer, epoch, trainloader)\n",
    "    epoch_end_time = time.time()\n",
    "    test(model, optimizer, epoch, valloader)\n",
    "    scheduler.step()\n",
    "    if epoch > 0:\n",
    "        print(\"Training for one epoch takes {:.3f}s\".format(epoch_end_time - epoch_start_time))\n",
    "        print(\"Speedup over baseline: {:.2f}\".format(baseline_time / (epoch_end_time - epoch_start_time)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization 3: Mixed precision training\n",
    "GPUs after Volta microarchitecture (V100, T4, A100, H100, etc) features TensorCores. \n",
    "\n",
    "These are much faster compute units than traditional 32-bit IEEE-754 floating numbers. Mixed precision leverages \n",
    "these tensor-cores and does additional numerical adjustments to recover the numerical discrepancies (although not identical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, grad_scalar, epoch, trainloader, prof=None):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with tqdm(total=len(trainloader), file=sys.stdout, ) as pbar:\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "    ####### OPTIMIZATION 3.1 #################\n",
    "            with torch.autocast(device_type=device):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "    ####### OPTIMIZATION 3.1 #################\n",
    "            \n",
    "    ####### OPTIMIZATION 3.2 #################\n",
    "            grad_scalar.scale(loss).backward()\n",
    "            grad_scalar.step(optimizer)\n",
    "            grad_scalar.update()\n",
    "    ####### OPTIMIZATION 3.2 #################\n",
    "        \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(-1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.set_description('[%3d]/[%3d]Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                        % (batch_idx, len(trainloader), train_loss/(batch_idx+1), \n",
    "                            100.*correct/total, correct, total),)\n",
    "            pbar.update(1)\n",
    "            \n",
    "            if prof is not None:\n",
    "                prof.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Xo6VNWKC0hi3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c0bd09248846bf99099926e1a10fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188286875dd14fc8a72c6ab6a68d016c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fbef9e05d2f49bd96f0d42f97a96302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2128234c4af64ec0a30235bfcd7cc91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for one epoch takes 12.690s\n",
      "Speedup over baseline: 6.36\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cuda.benchmark = True\n",
    "torch.backends.cuda.deterministic = False\n",
    "\n",
    "trainloader, valloader = get_loaders(256, 512)\n",
    "\n",
    "model = ResNet50(num_classes=100).to(device)\n",
    "model.train()\n",
    "\n",
    "####### OPTIMIZATION 3.3 #################\n",
    "model.to(memory_format=torch.channels_last)\n",
    "####### OPTIMIZATION 3.3 #################\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "grad_scalar = torch.cuda.amp.GradScaler()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model, optimizer, grad_scalar, epoch, trainloader)\n",
    "    epoch_end_time = time.time()\n",
    "    test(model, optimizer, epoch, valloader)\n",
    "    scheduler.step()\n",
    "    if epoch > 0:\n",
    "        print(\"Training for one epoch takes {:.3f}s\".format(epoch_end_time - epoch_start_time))\n",
    "        print(\"Speedup over baseline: {:.2f}\".format(baseline_time / (epoch_end_time - epoch_start_time)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization 4: torch.jit\n",
    "Just-in-time compilation is a technique to compile PyTorch models for better utilization.\n",
    "\n",
    "The details of jit require another session to explain, but the APIs are pretty simple, please see below. \n",
    "\n",
    "Jit works best with static input shapes, so we make the dataloader to `drop_last`, which keeps the batch size \n",
    "always consistent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(train_bs, val_bs,):\n",
    "\n",
    "  transform_train = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.RandomCrop(32, padding=4),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.GaussianBlur(3),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  transform_test = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  trainset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=True, download=True, transform=transform_train)\n",
    "  trainloader = torch.utils.data.DataLoader(\n",
    "      trainset, batch_size=train_bs, shuffle=True,\n",
    "      pin_memory=True,\n",
    "      num_workers=8,\n",
    "    ####### OPTIMIZATION 4.1 #################\n",
    "      drop_last=True,\n",
    "    ####### OPTIMIZATION 4.1 #################\n",
    "  )\n",
    "\n",
    "  testset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=False, download=True, transform=transform_test)\n",
    "  testloader = torch.utils.data.DataLoader(\n",
    "      testset, batch_size=val_bs, shuffle=False,\n",
    "      pin_memory=True,\n",
    "      num_workers=8,\n",
    "    ####### OPTIMIZATION 4.2 #################\n",
    "      drop_last=True,\n",
    "    ####### OPTIMIZATION 4.2 #################\n",
    "  )\n",
    "  \n",
    "  return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671d1109b7344545ab080723d7191908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d03aa8426c414dbb74cbe4feea849f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792f5c6dbc584ffdb1714c0cfedfbdbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113a54e2ebd0419dbd4eb0dbddfc7f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for one epoch takes 11.649s\n",
      "Speedup over baseline: 6.93\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader = get_loaders(256, 512)\n",
    "\n",
    "model = ResNet50(num_classes=100).to(device)\n",
    "model.train()\n",
    "model.to(memory_format=torch.channels_last)\n",
    "\n",
    "####### OPTIMIZATION 4.3 #################\n",
    "traced_model = torch.jit.trace(model, (torch.rand(256, 3, 32, 32, device=device),))\n",
    "####### OPTIMIZATION 4.3 #################\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "\n",
    "grad_scalar = torch.cuda.amp.GradScaler()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train(traced_model, optimizer, grad_scalar, epoch, trainloader)\n",
    "    epoch_end_time = time.time()\n",
    "    test(model, optimizer, epoch, valloader)\n",
    "    scheduler.step()\n",
    "    if epoch > 0:\n",
    "        print(\"Training for one epoch takes {:.3f}s\".format(epoch_end_time - epoch_start_time))\n",
    "        print(\"Speedup over baseline: {:.2f}\".format(baseline_time / (epoch_end_time - epoch_start_time)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization 5: CUDAGraph\n",
    "\n",
    "CUDAGraph captures the sequence of GPU operations and optimizes them into a single GPU operation. This reduces overhead significantly.\n",
    "\n",
    "CUDAGraph also requires static shapes and computation patterns, which have limited use-cases. Please use it with caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9886f4066f1a4063bb1994d475376f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb485c98f804c6a94a694250637ec57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b201fca4734d8b8c41464e08173fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26562162619e4f9e86c929ae9e348ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for one epoch takes 9.609s\n",
      "Speedup over baseline: 8.40\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader = get_loaders(256, 512)\n",
    "\n",
    "model = ResNet50(num_classes=100).to(device)\n",
    "model.train()\n",
    "model.to(memory_format=torch.channels_last)\n",
    "\n",
    "traced_model = torch.jit.trace(model, (torch.rand(256, 3, 32, 32, device=device),))\n",
    "\n",
    "####### OPTIMIZATION 5 #################\n",
    "with torch.amp.autocast(device_type=device, cache_enabled=False):\n",
    "    graphed_model = torch.cuda.make_graphed_callables(traced_model, (torch.rand(256, 3, 32, 32, device=device),))\n",
    "####### OPTIMIZATION 5 #################\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "\n",
    "grad_scalar = torch.cuda.amp.GradScaler()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train(graphed_model, optimizer, grad_scalar, epoch, trainloader)\n",
    "    epoch_end_time = time.time()\n",
    "    test(model, optimizer, epoch, valloader)\n",
    "    scheduler.step()\n",
    "    if epoch > 0:\n",
    "        print(\"Training for one epoch takes {:.3f}s\".format(epoch_end_time - epoch_start_time))\n",
    "        print(\"Speedup over baseline: {:.2f}\".format(baseline_time / (epoch_end_time - epoch_start_time)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "Optimizations are heavily dependent on your workload and metrics, and is fairly complex. The code changes above may look simple, but it was a significant engineering effort to interatively profile and subsequently modify the source code. One would argue that: a performance engineer can only be as good as the profiler she uses :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created by Xin Li (xin@centml.ai), adapted by Yubo Gao (ybgao@centml.ai) for ASPLOS '23.\n",
    "\n",
    "# Connect with us\n",
    "Please email xin@centml.ai for any questions!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "25d7c76b6736750e665ab5180c0b6f4170253858637861cc0a99401fc0f89047"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
