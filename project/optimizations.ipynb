{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook\n",
    "In this notebook, we will show you how we profile and optimize a canonical computer vision training instance: *ResNet50 + CIFAR100*. In the end, we would achive near 10x speedup from the baseline.\n",
    "\n",
    "The notebook is brokendown into \"Optimization stages\", were we incrementally permute our training pipeline to perform system-level optimization on different parts\n",
    "of the training logic. \n",
    "\n",
    "Please follow along this notebook, follow the comments that show ########## Optimization X ################### for code changes in each optimization stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install profiler dependencies\n",
    "!pip install -q torch_tb_profiler tensorboard==2.12.0 tensorboard-plugin-profile==2.11.2 tensorflow==2.12.0 protobuf==3.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5kcB0zwMCdLA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXYuWN4_gRh4"
   },
   "source": [
    "## Model\n",
    "We include a basic implementation of ResNet50 based on torchvision's implementation, but removes \n",
    "the extra boilerplate code for better readability.\n",
    "Please navigate to `model.py` to check model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DGfkrKemCl50"
   },
   "outputs": [],
   "source": [
    "from model import ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mef7QUjNgkcf"
   },
   "source": [
    "## Data\n",
    "For the notebook to run in a reasonable time, we pick CIFAR100 as our dataloader, which is an image dataset with 3x32x32 images from 100 classes.\n",
    "\n",
    "We select a few data-augmentation techniques, they include:\n",
    "* Crop\n",
    "* Horizontal Flip\n",
    "* Gaussian blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jSe003_Sglv3"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def get_loaders(train_bs, val_bs):\n",
    "\n",
    "  transform_train = transforms.Compose([\n",
    "      transforms.RandomCrop(32, padding=4),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.GaussianBlur(3),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  transform_test = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  trainset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=True, download=True, transform=transform_train)\n",
    "  trainloader = torch.utils.data.DataLoader(\n",
    "      trainset, batch_size=train_bs, shuffle=True)\n",
    "\n",
    "  testset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=False, download=True, transform=transform_test)\n",
    "  testloader = torch.utils.data.DataLoader(\n",
    "      testset, batch_size=val_bs, shuffle=False)\n",
    "  \n",
    "  return trainloader, testloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SV_reOX8gU9X"
   },
   "source": [
    "## Training\n",
    "This training loop below is a standard supervised image classification training procedure as suggested by PyTorch examples.\n",
    "Please skim over this quickly as the details (such as logging, and metrics reporting) don't matter as much for our workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nB0takEVh9E2"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from tqdm.notebook import  tqdm\n",
    "import sys, os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tcDAxY3AjX1Y"
   },
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "end_epoch = 2\n",
    "lr = 0.1\n",
    "best_acc = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "USprdxU8jhOI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0VnQ4n4zEJ2M"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, epoch, trainloader, prof=None):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with tqdm(total=len(trainloader), file=sys.stdout, ) as pbar:\n",
    "      for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "          inputs, targets = inputs.to(device), targets.to(device)\n",
    "          optimizer.zero_grad()\n",
    "          outputs = model(inputs)\n",
    "          loss = criterion(outputs, targets)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          train_loss += loss.item()\n",
    "          _, predicted = outputs.max(-1)\n",
    "          total += targets.size(0)\n",
    "          correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "          pbar.set_description('[%3d]/[%3d]Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                      % (batch_idx, len(trainloader), train_loss/(batch_idx+1), \n",
    "                          100.*correct/total, correct, total),)\n",
    "          pbar.update(1)\n",
    "          \n",
    "          if prof is not None:\n",
    "            prof.step()\n",
    "            if batch_idx == 20:\n",
    "              return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, optimizer, epoch, testloader):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "      with tqdm(total=len(testloader), file=sys.stdout) as pbar:\n",
    "\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(-1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.set_description('[%3d]/[%3d]Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                         % (batch_idx, len(testloader), test_loss/(batch_idx+1), \n",
    "                            100.*correct/total, correct, total),)\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "The baseline simply runs the training loop for 2 epochs, and reports the training time for the second epoch (when things are more stable).\n",
    "\n",
    "We use `tqdm` to report training progression for each epoch, As it trains, you should notice the loss on the left of the progress bar to decrease, as well as the iteration time on the right of the progress bar.\n",
    "\n",
    "The expected runtime for this snippet is 160 (80*2) seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "id": "LxanaJZzEndq",
    "outputId": "015b9a5d-98fc-4379-83b0-bfe6f6fc73c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f8a677dd5f49ce911d2d7674550a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3e3d9f1e9b42e98dc60c76ee5af694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "306749a06b9c48178a17a2437719f033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71d451c95404e589907575043e53d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for one epoch takes 78.477s\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader = get_loaders(128, 128)\n",
    "import torchvision\n",
    "model = ResNet50(num_classes=100).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model, optimizer, epoch, trainloader)\n",
    "    epoch_end_time = time.time()\n",
    "    \n",
    "    test(model, optimizer, epoch, valloader)\n",
    "    scheduler.step()\n",
    "    if epoch > 0:\n",
    "        print(\"Training for one epoch takes {:.3f}s\".format(epoch_end_time - epoch_start_time))\n",
    "\n",
    "baseline_time = epoch_end_time - epoch_start_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling with torch.profiler\n",
    "\n",
    "We choose to profile with the built-in PyTorch profiler for its ease of use. \n",
    "\n",
    "For more detailed profiling, you could also use `vtune` (for Intel CPU), `nsys` (for NVIDIA GPU), and\n",
    "other vendor-specific profiling tools. \n",
    "\n",
    "However, they require more careful installation and\n",
    "launching procedures, which we do not have the resources to cover here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a182efc318848999bc1eb6132a94d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:343] Profiler is not initialized: skipping step() invocation\n",
      "STAGE:2023-03-25 06:48:52 11607:11607 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "[W CPUAllocator.cpp:235] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event\n",
      "STAGE:2023-03-25 06:48:53 11607:11607 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-03-25 06:48:53 11607:11607 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader = get_loaders(128, 128)\n",
    "\n",
    "model = ResNet50(num_classes=100).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=5e-4)\n",
    "\n",
    "with torch.profiler.profile(\n",
    "        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "        schedule=torch.profiler.schedule(skip_first=10, wait=5, warmup=1, active=1, repeat=1),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./profile/baseline'),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True\n",
    ") as prof:\n",
    "    train(model, optimizer, 0, trainloader, prof)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open profiled results\n",
    "\n",
    "* Inside the folder `asplos23-tutorial/project`, run `tensorboard --logdir profile --bind_all` to run TensorBoard.\n",
    "* Navigate to `<machine_ip>:6006`, then select `pytorch_profiler` from the dropdown menu.\n",
    "* On the left under `Views`, select `Trace` to view the execution trace. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization1: re-order augmentation \n",
    "The first optimization concerns with data-augmentation.\n",
    "While many augmentation techniques are insensitive to ordering (i.e. crop after blur is identical to blur after crop),\n",
    "the performance implications are significant.\n",
    "\n",
    "Instead of issuing `ToTensor` last, we issue `ToTensor` first in the data augmentation pipeline, this would allow\n",
    "subsequent operations to run with `Tensor` objects which have better hardware utilization due to its better implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(train_bs, val_bs,):\n",
    "\n",
    "  transform_train = transforms.Compose([\n",
    "    ####### OPTIMIZATION 1 #################\n",
    "      transforms.ToTensor(),\n",
    "    ####### OPTIMIZATION 1 #################\n",
    "      transforms.RandomCrop(32, padding=4),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.GaussianBlur(3),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  transform_test = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  trainset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=True, download=True, transform=transform_train)\n",
    "  trainloader = torch.utils.data.DataLoader(\n",
    "      trainset, batch_size=train_bs, shuffle=True)\n",
    "\n",
    "  testset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=False, download=True, transform=transform_test)\n",
    "  testloader = torch.utils.data.DataLoader(\n",
    "      testset, batch_size=val_bs, shuffle=False)\n",
    "  \n",
    "  return trainloader, testloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "s2KGJdWLpNpa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b251956e3ffe474ea0c99a1da85bc4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c1b4a0ccc44b0a851862cebb238a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e37217be2654675b1638aa91d807f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e36294489d485b8911f12e57448e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for one epoch takes 60.969s\n",
      "Speedup over baseline: 1.29\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(num_classes=100).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "trainloader, valloader = get_loaders(128, 128)\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model, optimizer, epoch, trainloader)\n",
    "    epoch_end_time = time.time()\n",
    "    test(model, optimizer, epoch, valloader)\n",
    "    scheduler.step()\n",
    "    if epoch > 0:\n",
    "        print(\"Training for one epoch takes {:.3f}s\".format(epoch_end_time - epoch_start_time))\n",
    "        print(\"Speedup over baseline: {:.2f}\".format(baseline_time / (epoch_end_time - epoch_start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization 2: pin_memory, pre-fetching, and batch_size\n",
    "By default, PyTorch does not enable data pre-fetching or loading data with multiple CPUs.\n",
    "\n",
    "To enable this, we need to set the `num_workers` argument in the dataloader.\n",
    "For a single GPU training setup, the best number is `number of cpus - 1 on your machine (7 in this case)`.\n",
    "\n",
    "Similarly, for GPU tensors, `pin_memory=True` would allow CPU tensors to be directly created in the pinned memory region,\n",
    "which is then copied to the GPU. Otherwise, we would incur an extra CPU-CPU copy.\n",
    "\n",
    "Lastly, batch size should be increased to the maximum of what your algorithm allows (for convergence) and what your hardware\n",
    "allows (before getting out of memory) for the best GPU utilization due to increased parallelism and memory reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(train_bs, val_bs,):\n",
    "\n",
    "  transform_train = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.RandomCrop(32, padding=4),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.GaussianBlur(3),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  transform_test = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  trainset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=True, download=True, transform=transform_train)\n",
    "  trainloader = torch.utils.data.DataLoader(\n",
    "    ####### OPTIMIZATION 2.1 #################\n",
    "      trainset, batch_size=train_bs, shuffle=True,\n",
    "      pin_memory=True,\n",
    "      num_workers=7,\n",
    "    ####### OPTIMIZATION 2.1 #################\n",
    "  )\n",
    "\n",
    "  testset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=False, download=True, transform=transform_test)\n",
    "  testloader = torch.utils.data.DataLoader(\n",
    "    ####### OPTIMIZATION 2 #################\n",
    "      testset, batch_size=val_bs, shuffle=False,\n",
    "      pin_memory=True,\n",
    "      num_workers=7,\n",
    "    ####### OPTIMIZATION 2 #################\n",
    "  )\n",
    "  \n",
    "  return trainloader, testloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DS6-O6yj0QVY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7414bb86ff3c4cdf9e1af90f484bffe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24eb4366eb24c758ef855c4ccd44716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2fc898ecf642d79fc2ca02911c6ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179262de84dd4206b79a9259fc7035ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for one epoch takes 22.582s\n",
      "Speedup over baseline: 3.48\n"
     ]
    }
   ],
   "source": [
    "####### OPTIMIZATION 2.2 #################\n",
    "trainloader, valloader = get_loaders(256, 512)\n",
    "####### OPTIMIZATION 2.2 #################\n",
    "\n",
    "model = ResNet50(num_classes=100).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model, optimizer, epoch, trainloader)\n",
    "    epoch_end_time = time.time()\n",
    "    test(model, optimizer, epoch, valloader)\n",
    "    scheduler.step()\n",
    "    if epoch > 0:\n",
    "        print(\"Training for one epoch takes {:.3f}s\".format(epoch_end_time - epoch_start_time))\n",
    "        print(\"Speedup over baseline: {:.2f}\".format(baseline_time / (epoch_end_time - epoch_start_time)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization 3: Mixed precision training\n",
    "GPUs after Volta microarchitecture (V100, T4, A100, H100, etc) features TensorCores. \n",
    "\n",
    "These are much faster compute units than traditional 32-bit IEEE-754 floating numbers. Mixed precision leverages \n",
    "these tensor-cores and does additional numerical adjustments to recover the numerical discrepancies (although not identical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, grad_scalar, epoch, trainloader, prof=None):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with tqdm(total=len(trainloader), file=sys.stdout, ) as pbar:\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "    ####### OPTIMIZATION 3.1 #################\n",
    "            with torch.autocast(device_type=device):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "    ####### OPTIMIZATION 3.1 #################\n",
    "            \n",
    "    ####### OPTIMIZATION 3.2 #################\n",
    "            grad_scalar.scale(loss).backward()\n",
    "            grad_scalar.step(optimizer)\n",
    "            grad_scalar.update()\n",
    "    ####### OPTIMIZATION 3.2 #################\n",
    "        \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(-1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.set_description('[%3d]/[%3d]Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                        % (batch_idx, len(trainloader), train_loss/(batch_idx+1), \n",
    "                            100.*correct/total, correct, total),)\n",
    "            pbar.update(1)\n",
    "            \n",
    "            if prof is not None:\n",
    "                prof.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Xo6VNWKC0hi3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34bddef56d80478c948186af9b424f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed7b578ecc746bc99c1229a50893d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de7b3b17e6d4d9d9571dd73a1e56ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a88db639ed4b7398b9396c4c0a95a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for one epoch takes 11.938s\n",
      "Speedup over baseline: 6.57\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cuda.benchmark = True\n",
    "torch.backends.cuda.deterministic = False\n",
    "\n",
    "trainloader, valloader = get_loaders(256, 512)\n",
    "\n",
    "model = ResNet50(num_classes=100).to(device)\n",
    "model.train()\n",
    "\n",
    "####### OPTIMIZATION 3.3 #################\n",
    "model.to(memory_format=torch.channels_last)\n",
    "####### OPTIMIZATION 3.3 #################\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "grad_scalar = torch.cuda.amp.GradScaler()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model, optimizer, grad_scalar, epoch, trainloader)\n",
    "    epoch_end_time = time.time()\n",
    "    test(model, optimizer, epoch, valloader)\n",
    "    scheduler.step()\n",
    "    if epoch > 0:\n",
    "        print(\"Training for one epoch takes {:.3f}s\".format(epoch_end_time - epoch_start_time))\n",
    "        print(\"Speedup over baseline: {:.2f}\".format(baseline_time / (epoch_end_time - epoch_start_time)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization 4: torch.jit\n",
    "Just-in-time compilation is a technique to compile PyTorch models for better utilization.\n",
    "\n",
    "The details of jit require another session to explain, but the APIs are pretty simple, please see below. \n",
    "\n",
    "Jit works best with static input shapes, so we make the dataloader to `drop_last`, which keeps the batch size \n",
    "always consistent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(train_bs, val_bs,):\n",
    "\n",
    "  transform_train = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.RandomCrop(32, padding=4),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.GaussianBlur(3),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  transform_test = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  trainset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=True, download=True, transform=transform_train)\n",
    "  trainloader = torch.utils.data.DataLoader(\n",
    "      trainset, batch_size=train_bs, shuffle=True,\n",
    "      pin_memory=True,\n",
    "      num_workers=8,\n",
    "    ####### OPTIMIZATION 4.1 #################\n",
    "      drop_last=True,\n",
    "    ####### OPTIMIZATION 4.1 #################\n",
    "  )\n",
    "\n",
    "  testset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=False, download=True, transform=transform_test)\n",
    "  testloader = torch.utils.data.DataLoader(\n",
    "      testset, batch_size=val_bs, shuffle=False,\n",
    "      pin_memory=True,\n",
    "      num_workers=8,\n",
    "    ####### OPTIMIZATION 4.2 #################\n",
    "      drop_last=True,\n",
    "    ####### OPTIMIZATION 4.2 #################\n",
    "  )\n",
    "  \n",
    "  return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05237b459e4f462f856edd98b48158f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c4ed0655b24af6bd5ad5f8e1e5679c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54c36339dc844ef8247f3c7ba0e3f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5218bbc1824426289a397b18b541e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for one epoch takes 11.360s\n",
      "Speedup over baseline: 6.91\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader = get_loaders(256, 512)\n",
    "\n",
    "model = ResNet50(num_classes=100).to(device)\n",
    "model.train()\n",
    "model.to(memory_format=torch.channels_last)\n",
    "\n",
    "####### OPTIMIZATION 4.3 #################\n",
    "traced_model = torch.jit.trace(model, (torch.rand(256, 3, 32, 32, device=device),))\n",
    "####### OPTIMIZATION 4.3 #################\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "\n",
    "grad_scalar = torch.cuda.amp.GradScaler()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train(traced_model, optimizer, grad_scalar, epoch, trainloader)\n",
    "    epoch_end_time = time.time()\n",
    "    test(model, optimizer, epoch, valloader)\n",
    "    scheduler.step()\n",
    "    if epoch > 0:\n",
    "        print(\"Training for one epoch takes {:.3f}s\".format(epoch_end_time - epoch_start_time))\n",
    "        print(\"Speedup over baseline: {:.2f}\".format(baseline_time / (epoch_end_time - epoch_start_time)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization 5: CUDAGraph\n",
    "\n",
    "CUDAGraph captures the sequence of GPU operations and optimizes them into a single GPU operation. This reduces overhead significantly.\n",
    "\n",
    "CUDAGraph also requires static shapes and computation patterns, which have limited use-cases. Please use it with caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328490c1d5234b81b94d2e59fe9b1faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28efa7e8180422284436c81366163b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba63053bcc0450886191563fa3ee8e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d15f582408441c1b6adbc36c32f0538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for one epoch takes 9.217s\n",
      "Speedup over baseline: 8.51\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader = get_loaders(256, 512)\n",
    "\n",
    "model = ResNet50(num_classes=100).to(device)\n",
    "model.train()\n",
    "model.to(memory_format=torch.channels_last)\n",
    "\n",
    "traced_model = torch.jit.trace(model, (torch.rand(256, 3, 32, 32, device=device),))\n",
    "\n",
    "####### OPTIMIZATION 5 #################\n",
    "with torch.amp.autocast(device_type=device, cache_enabled=False):\n",
    "    graphed_model = torch.cuda.make_graphed_callables(traced_model, (torch.rand(256, 3, 32, 32, device=device),))\n",
    "####### OPTIMIZATION 5 #################\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "\n",
    "grad_scalar = torch.cuda.amp.GradScaler()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train(graphed_model, optimizer, grad_scalar, epoch, trainloader)\n",
    "    epoch_end_time = time.time()\n",
    "    test(model, optimizer, epoch, valloader)\n",
    "    scheduler.step()\n",
    "    if epoch > 0:\n",
    "        print(\"Training for one epoch takes {:.3f}s\".format(epoch_end_time - epoch_start_time))\n",
    "        print(\"Speedup over baseline: {:.2f}\".format(baseline_time / (epoch_end_time - epoch_start_time)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "Optimizations are heavily dependent on your workload and metrics, and is fairly complex. The code changes above may look simple, but it was a significant engineering effort to interatively profile and subsequently modify the source code. One would argue that: a performance engineer can only be as good as the profiler she uses :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created by Xin Li (xin@centml.ai), adapted by Yubo Gao (ybgao@centml.ai) for ASPLOS '23.\n",
    "\n",
    "# Connect with us\n",
    "Please email xin@centml.ai for any questions!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "25d7c76b6736750e665ab5180c0b6f4170253858637861cc0a99401fc0f89047"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
